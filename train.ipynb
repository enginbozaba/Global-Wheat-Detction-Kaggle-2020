{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T21:09:49.632293Z",
     "start_time": "2020-06-12T21:09:42.088215Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from modules.GWD_data import WheatDataset\n",
    "from modules.metric import calculate_image_precision\n",
    "from modules.utils import collate_fn, plot_boxes, get_model_name, format_prediction_string, remove_blanks, is_contain_blanks\n",
    "from config import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T21:09:51.672128Z",
     "start_time": "2020-06-12T21:09:50.854390Z"
    }
   },
   "outputs": [],
   "source": [
    "conf = config()\n",
    "torch.random.manual_seed(5)\n",
    "writer = SummaryWriter(\"runs/Edet_4_Test_run\") #\n",
    "\n",
    "\n",
    "WD_Train = WheatDataset(conf)\n",
    "WD_Valid = WheatDataset(conf, train=False)\n",
    "WD_Train_Loader = torch.utils.data.DataLoader(WD_Train, batch_size=conf.BATH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "WD_Valid_Loader = torch.utils.data.DataLoader(WD_Valid, batch_size=conf.BATH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T21:09:52.603929Z",
     "start_time": "2020-06-12T21:09:52.590933Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes=2):\n",
    "    print('New Model ')\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, progress=True, pretrained_backbone=True)\n",
    "    model.roi_heads.box_predictor.cls_score = torch.nn.Linear(model.roi_heads.box_predictor.cls_score.in_features, num_classes, bias=True)\n",
    "    model.roi_heads.box_predictor.bbox_pred = torch.nn.Linear(model.roi_heads.box_predictor.bbox_pred.in_features, num_classes*4, bias=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:55:01.068989Z",
     "start_time": "2020-05-20T22:54:52.711150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model \n"
     ]
    }
   ],
   "source": [
    "#model_path=None\n",
    "#GWD_Model = torch.load(model_path) if model_path else get_model()\n",
    "#GWD_Model.load_state_dict(torch.load('model/model_rc/fasterrcnn_resnet50_fpn_best.pth'))\n",
    "#GWD_Model.to(conf.DEVICE)\n",
    "#EPOCH = int(model_path.split('/')[-1].split('_')[2])+1 if model_path else 0\n",
    "\n",
    "#params = [p for p in GWD_Model.parameters() if p.requires_grad]\n",
    "#optimizer = torch.optim.SGD(params, lr=0.0002,momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T19:59:53.770481Z",
     "start_time": "2020-05-21T19:59:52.261815Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = 'model/model_rc/GWD_EPOCH_19_SCORE_0.0000_LOSS_201.4089.pt'\n",
    "GWD_Model = torch.load(model_path) if model_path else get_model()\n",
    "GWD_Model.to(conf.DEVICE)\n",
    "EPOCH = int(model_path.split('/')[-1].split('_')[2])+1 if model_path else 0\n",
    "\n",
    "params = [p for p in GWD_Model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.0005,momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T23:15:19.923467Z",
     "start_time": "2020-05-21T20:01:02.776526Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267edd3bbed8440f89f915643efa2830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599dc370e58d442196ed3ffb50ed3ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0545b1659e0244acbdf133822c863d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3334966be57a45ff8445a1e9f1b9a429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20054061ae024c85a5487f6f2ffc0c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467f42c0eebe484c9c71284511b9b17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e29262fc2a643c68e8bf49411d67744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bae5b0810942a2b61084a692ef236b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0cf412315c4423b8910346ef809da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a170ec5e3c040a086fbea176758f5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27cbeaad8eb48b0bfe525c96e7c0120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_iter=len(WD_Train_Loader)*(EPOCH)\n",
    "\n",
    "for i in tqdm_notebook(range(EPOCH, 30, 1)):\n",
    "    \n",
    "    _epoch_loss=0\n",
    "    _ = GWD_Model.train()\n",
    "    for images, targets in tqdm_notebook(WD_Train_Loader):\n",
    "        \n",
    "        #if not is_contain_blanks(targets):\n",
    "        try:\n",
    "            images = [torch.tensor(image, dtype = torch.float32).to(conf.DEVICE) for image in images]\n",
    "            targets = [{k: torch.tensor(v).to(conf.DEVICE) for k, v in target.items()} for target in targets]\n",
    "\n",
    "            loss_dictionary = GWD_Model(images,targets)\n",
    "            summed_loss = sum(loss for loss in loss_dictionary.values())\n",
    "            summed_loss_value = summed_loss.item()\n",
    "\n",
    "\n",
    "            if math.isfinite(summed_loss_value):\n",
    "                optimizer.zero_grad()\n",
    "                summed_loss.backward()\n",
    "                optimizer.step()\n",
    "                _epoch_loss+=summed_loss_value\n",
    "\n",
    "            else:\n",
    "                print('Loss is undefined:',summed_loss_value,'   skipping BackProp for step no:',_iter)\n",
    "                print(loss_dictionary)\n",
    "\n",
    "\n",
    "            writer.add_scalar('Running Loss/Summed', summed_loss_value, _iter)\n",
    "            writer.add_scalar('Running Loss/Classifier', loss_dictionary['loss_classifier'].item(), _iter)\n",
    "            writer.add_scalar('Running Loss/Box_Regress', loss_dictionary['loss_box_reg'].item(), _iter)\n",
    "            writer.add_scalar('Running Loss/Objectness', loss_dictionary['loss_objectness'].item(), _iter)\n",
    "            writer.add_scalar('Running Loss/RPN_Box_regress', loss_dictionary['loss_rpn_box_reg'].item(), _iter)\n",
    "            \n",
    "        except:\n",
    "            print('Some weird shape error due to blank images, but handeled')\n",
    "        \n",
    "        _iter+=1\n",
    "        \n",
    "    torch.save(GWD_Model, 'model/model_rc/'+get_model_name(i, 0, _epoch_loss))\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDet-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:27.375311Z",
     "start_time": "2020-06-14T18:04:19.209697Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import traceback\n",
    "import gc\n",
    "import sys\n",
    "sys.path.insert(1, 'models/EfficientDet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:40.320394Z",
     "start_time": "2020-06-14T18:04:31.259387Z"
    }
   },
   "outputs": [],
   "source": [
    "from edet import edet#, freeze_backbone\n",
    "from efficientdet.loss import FocalLoss\n",
    "from modules.edet_utils import feeze_backbone\n",
    "from modules.edet_utils import WheatDataset_edet, Resizer, Normalizer, collater\n",
    "from config import config\n",
    "conf = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:41.094685Z",
     "start_time": "2020-06-14T18:04:40.390369Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "obj_list = ['wheat']\n",
    "compound_coef = 4\n",
    "model = edet(compound_coef, obj_list)\n",
    "weight_dir = 'D:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\saved_weights\\Edet\\d'+str(compound_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:44.244950Z",
     "start_time": "2020-06-14T18:04:42.689122Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_weight_path = weight_dir+'\\last.pth'\n",
    "try:\n",
    "    ret = model.load_state_dict(torch.load(saved_weight_path) , strict=False)\n",
    "except RuntimeError as e:\n",
    "    print(f'[Warning] Ignoring {e}')\n",
    "    print('\\n\\nThis error caused because last layer size don\\'t match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:44.331921Z",
     "start_time": "2020-06-14T18:04:44.322924Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:57.302414Z",
     "start_time": "2020-06-14T18:04:56.233625Z"
    }
   },
   "outputs": [],
   "source": [
    "mean= [0.485, 0.456, 0.406]\n",
    "std= [0.229, 0.224, 0.225]\n",
    "\n",
    "Data_Transform = transforms.Compose(\n",
    "    [Normalizer(mean=mean, std=std),\n",
    "     Resizer(input_sizes[compound_coef])])\n",
    "\n",
    "WD_Train = WheatDataset_edet(conf, transform = Data_Transform)\n",
    "WD_Valid = WheatDataset_edet(conf, train=False)\n",
    "WD_Train_Loader = DataLoader(WD_Train,\n",
    "                             batch_size=conf.BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             collate_fn=collater)\n",
    "WD_Valid_Loader = DataLoader(WD_Valid,\n",
    "                             batch_size=conf.BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             collate_fn=collater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:58.574625Z",
     "start_time": "2020-06-14T18:04:58.092781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[-1.6727, -1.6506, -1.4036],\n",
       "          [-1.6042, -1.5805, -1.3339],\n",
       "          [-1.5014, -1.4755, -1.2293],\n",
       "          ...,\n",
       "          [-1.0390, -0.3375, -0.6367],\n",
       "          [-1.0219, -0.3375, -0.6541],\n",
       "          [-1.0390, -0.3375, -0.6715]],\n",
       " \n",
       "         [[-1.7069, -1.6856, -1.4384],\n",
       "          [-1.6555, -1.6331, -1.3861],\n",
       "          [-1.5528, -1.5280, -1.2816],\n",
       "          ...,\n",
       "          [-1.0562, -0.4251, -0.6367],\n",
       "          [-1.1075, -0.4076, -0.7064],\n",
       "          [-1.1075, -0.4076, -0.7064]],\n",
       " \n",
       "         [[-1.7583, -1.7206, -1.4907],\n",
       "          [-1.7069, -1.6856, -1.4384],\n",
       "          [-1.6213, -1.5980, -1.3513],\n",
       "          ...,\n",
       "          [-1.0733, -0.4426, -0.6018],\n",
       "          [-1.0733, -0.4426, -0.6018],\n",
       "          [-1.0733, -0.4426, -0.6018]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.1589, -1.0903, -0.8807],\n",
       "          [-1.1589, -1.0903, -0.8807],\n",
       "          [-1.1589, -1.0903, -0.8807],\n",
       "          ...,\n",
       "          [ 1.6153,  1.8333,  0.7402],\n",
       "          [ 1.6667,  1.8859,  0.8274],\n",
       "          [ 1.5810,  1.8333,  0.8099]],\n",
       " \n",
       "         [[-1.0904, -1.0203, -0.8110],\n",
       "          [-1.1075, -1.0378, -0.8284],\n",
       "          [-1.1247, -1.0553, -0.8458],\n",
       "          ...,\n",
       "          [ 1.2728,  1.4832,  0.3916],\n",
       "          [ 1.3584,  1.5707,  0.5136],\n",
       "          [ 1.3755,  1.6232,  0.5659]],\n",
       " \n",
       "         [[-1.0390, -0.9853, -0.7587],\n",
       "          [-1.0562, -1.0028, -0.7761],\n",
       "          [-1.0733, -1.0203, -0.7936],\n",
       "          ...,\n",
       "          [ 0.9646,  1.1681,  0.0431],\n",
       "          [ 1.0159,  1.2206,  0.1651],\n",
       "          [ 1.0844,  1.3256,  0.2871]]]),\n",
       " 'annot': tensor([[ 834.,  222.,  890.,  258.,    0.],\n",
       "         [ 226.,  548.,  356.,  606.,    0.],\n",
       "         [ 377.,  504.,  451.,  664.,    0.],\n",
       "         [ 834.,   95.,  943.,  202.,    0.],\n",
       "         [  26.,  144.,  150.,  261.,    0.],\n",
       "         [ 569.,  382.,  688.,  493.,    0.],\n",
       "         [  52.,  602.,  134.,  647.,    0.],\n",
       "         [ 627.,  302.,  749.,  377.,    0.],\n",
       "         [ 412.,  367.,  480.,  449.,    0.],\n",
       "         [ 953.,  220., 1009.,  323.,    0.],\n",
       "         [  30.,   70.,  156.,  203.,    0.],\n",
       "         [  35.,  541.,   81.,  587.,    0.],\n",
       "         [ 103.,   60.,  220.,  143.,    0.],\n",
       "         [ 417.,    4.,  527.,   95.,    0.],\n",
       "         [ 764.,  299.,  883.,  392.,    0.],\n",
       "         [ 539.,   58.,  597.,  188.,    0.],\n",
       "         [ 139.,  274.,  260.,  350.,    0.],\n",
       "         [ 461.,  634.,  579.,  698.,    0.],\n",
       "         [ 215.,  634.,  328.,  709.,    0.],\n",
       "         [ 134.,  903.,  261.,  952.,    0.],\n",
       "         [ 737.,  545.,  824.,  593.,    0.],\n",
       "         [ 292.,  930.,  335.,  976.,    0.],\n",
       "         [   0.,  827.,   86.,  885.,    0.],\n",
       "         [ 324.,   44.,  381.,  114.,    0.],\n",
       "         [ 663.,  794.,  779.,  858.,    0.],\n",
       "         [ 325.,  730.,  401.,  802.,    0.],\n",
       "         [ 155.,  554.,  229.,  624.,    0.],\n",
       "         [ 783.,  833.,  853.,  924.,    0.],\n",
       "         [ 534.,   46.,  607.,  270.,    0.],\n",
       "         [ 155.,  281.,  261.,  419.,    0.],\n",
       "         [ 101.,  240.,  183.,  315.,    0.],\n",
       "         [ 583.,  329.,  663.,  412.,    0.],\n",
       "         [  36.,  595.,  128.,  636.,    0.],\n",
       "         [   0.,  487.,   46.,  558.,    0.],\n",
       "         [  25.,  482.,   76.,  542.,    0.],\n",
       "         [ 160.,  689.,  300.,  763.,    0.],\n",
       "         [ 202.,  702.,  306.,  786.,    0.],\n",
       "         [ 852.,  677.,  967.,  835.,    0.],\n",
       "         [ 904.,  700.,  977.,  820.,    0.],\n",
       "         [ 175.,  866.,  257.,  909.,    0.],\n",
       "         [ 612.,  882.,  827., 1018.,    0.],\n",
       "         [ 675.,  986.,  806., 1024.,    0.],\n",
       "         [ 959.,  869.,  982.,  900.,    0.],\n",
       "         [ 600.,  723.,  821.,  804.,    0.],\n",
       "         [ 575.,  146.,  647.,  267.,    0.],\n",
       "         [ 945.,  193., 1002.,  238.,    0.],\n",
       "         [ 216.,  440.,  262.,  460.,    0.]], dtype=torch.float64),\n",
       " 'scale': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WD_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:05:12.023115Z",
     "start_time": "2020-06-14T18:05:12.003121Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelWithLoss(nn.Module):\n",
    "    def __init__(self, model, debug=False):\n",
    "        super().__init__()\n",
    "        self.criterion = FocalLoss()\n",
    "        self.model = model\n",
    "        self.debug = debug\n",
    "\n",
    "    def forward(self, imgs, annotations, obj_list=None):\n",
    "        _, regression, classification, anchors = self.model(imgs)\n",
    "        if self.debug:\n",
    "            cls_loss, reg_loss = self.criterion(classification, regression, anchors, annotations,\n",
    "                                                imgs=imgs, obj_list=obj_list)\n",
    "        else:\n",
    "            cls_loss, reg_loss = self.criterion(classification, regression, anchors, annotations)\n",
    "        return cls_loss, reg_loss\n",
    "model = ModelWithLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:05:58.200449Z",
     "start_time": "2020-06-14T18:05:50.182969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2af1731918d42f4a35e483bc4c9193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2698), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 93, in forward\n",
      "    x = self._project_conv(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils_extra.py\", line 44, in forward\n",
      "    x = F.pad(x, [left, right, top, bottom])\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 3391, in _pad\n",
      "    return _VF.constant_pad_nd(input, pad, value)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.31 GiB already allocated; 14.83 MiB free; 9.47 GiB reserved in total by PyTorch)\n",
      "\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.31 GiB already allocated; 14.83 MiB free; 9.47 GiB reserved in total by PyTorch)\n",
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 81, in forward\n",
      "    x = self._depthwise_conv(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils_extra.py\", line 44, in forward\n",
      "    x = F.pad(x, [left, right, top, bottom])\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 3391, in _pad\n",
      "    return _VF.constant_pad_nd(input, pad, value)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.28 GiB already allocated; 4.58 MiB free; 9.46 GiB reserved in total by PyTorch)\n",
      "\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.28 GiB already allocated; 4.58 MiB free; 9.46 GiB reserved in total by PyTorch)\n",
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 93, in forward\n",
      "    x = self._project_conv(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils_extra.py\", line 44, in forward\n",
      "    x = F.pad(x, [left, right, top, bottom])\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 3391, in _pad\n",
      "    return _VF.constant_pad_nd(input, pad, value)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 12.00 GiB total capacity; 9.07 GiB already allocated; 4.16 MiB free; 9.23 GiB reserved in total by PyTorch)\n",
      "\n",
      "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 12.00 GiB total capacity; 9.07 GiB already allocated; 4.16 MiB free; 9.23 GiB reserved in total by PyTorch)\n",
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 83, in forward\n",
      "    x = self._swish(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils.py\", line 54, in forward\n",
      "    return SwishImplementation.apply(x)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils.py\", line 41, in forward\n",
      "    result = i * torch.sigmoid(i)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.30 GiB already allocated; 12.98 MiB free; 9.46 GiB reserved in total by PyTorch)\n",
      "\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.30 GiB already allocated; 12.98 MiB free; 9.46 GiB reserved in total by PyTorch)\n",
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 83, in forward\n",
      "    x = self._swish(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils.py\", line 54, in forward\n",
      "    return SwishImplementation.apply(x)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils.py\", line 41, in forward\n",
      "    result = i * torch.sigmoid(i)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.30 GiB already allocated; 18.83 MiB free; 9.46 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.30 GiB already allocated; 18.83 MiB free; 9.46 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-98f2bf198274>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mcls_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mcls_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mreg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-b16f1436717e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, imgs, annotations, obj_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             cls_loss, reg_loss = self.criterion(classification, regression, anchors, annotations,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\backbone.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mmax_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\efficientdet\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\efficientnet\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mx_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mx_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_se_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mx_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[0mx_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_se_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\efficientnet\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMemoryEfficientSwish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSwishImplementation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\efficientnet\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, i)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/Edet_4_Test_run\")\n",
    "model.train()\n",
    "model.to(conf.DEVICE)\n",
    "\n",
    "last_epoch = 0\n",
    "# TODO: Extract last epoch from saved model name\n",
    "current_iter = max(0, last_epoch*len(WD_Train_Loader))\n",
    "\n",
    "for epoch in range(last_epoch, 2, 1):\n",
    "\n",
    "    epoch_loss = []\n",
    "    progress_bar = tqdm(WD_Train_Loader)\n",
    "        \n",
    "    for _, data in enumerate(progress_bar):\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # TODO: targets to required format\n",
    "        try:\n",
    "            \n",
    "            images = data['img']\n",
    "            targets = data['annot']\n",
    "\n",
    "            images = images.to(conf.DEVICE)\n",
    "            targets = targets.to(conf.DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
    "            cls_loss = cls_loss.mean()\n",
    "            reg_loss = reg_loss.mean()\n",
    "\n",
    "            loss = cls_loss + reg_loss\n",
    "            if loss == 0 or not torch.isfinite(loss):\n",
    "                print('loss is 0 or infinite')\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(float(loss))\n",
    "\n",
    "            current_iter+=1\n",
    "            writer.add_scalar('Running Loss/Summed', loss, current_iter)\n",
    "            writer.add_scalar('Running Loss/Classifier', cls_loss, current_iter)\n",
    "            writer.add_scalar('Running Loss/Box_Regress', reg_loss, current_iter)\n",
    "            writer.add_scalar('Running LR', optimizer.param_groups[0]['lr'], current_iter)\n",
    "\n",
    "            progress_bar.set_description(\n",
    "                'Epoch: {}, Images: {}, Cls_loss: {:.5f}, Reg_loss: {:.5f}, Total_loss: {:.5f}'\n",
    "                .format(epoch, _ * conf.BATCH_SIZE, cls_loss.item(),reg_loss.item(), loss.item()))\n",
    "\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print('[Error]', traceback.format_exc())\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "    save_model_path = 'GWD_EDET{}_EPOCH_{}_SCORE_{:.5f}_LOSS_{:.5f}.pth'.format(compound_coef, epoch, 0, np.mean(epoch_loss))\n",
    "    torch.save(model.state_dict(), weight_dir+'/'+save_model_path)\n",
    "    torch.save(model.state_dict(), weight_dir+'/last.pth')\n",
    "    print('model_saved')\n",
    "    scheduler.step(np.mean(epoch_loss))\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
