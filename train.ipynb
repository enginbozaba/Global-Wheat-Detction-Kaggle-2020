{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T21:09:49.632293Z",
     "start_time": "2020-06-12T21:09:42.088215Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from modules.GWD_data import WheatDataset\n",
    "from modules.metric import calculate_image_precision\n",
    "from modules.utils import collate_fn, plot_boxes, get_model_name, format_prediction_string, remove_blanks, is_contain_blanks\n",
    "from config import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T21:09:51.672128Z",
     "start_time": "2020-06-12T21:09:50.854390Z"
    }
   },
   "outputs": [],
   "source": [
    "conf = config()\n",
    "torch.random.manual_seed(5)\n",
    "writer = SummaryWriter(\"runs/Edet_4_Test_run\") #\n",
    "\n",
    "\n",
    "WD_Train = WheatDataset(conf)\n",
    "WD_Valid = WheatDataset(conf, train=False)\n",
    "WD_Train_Loader = torch.utils.data.DataLoader(WD_Train, batch_size=conf.BATH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "WD_Valid_Loader = torch.utils.data.DataLoader(WD_Valid, batch_size=conf.BATH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T21:09:52.603929Z",
     "start_time": "2020-06-12T21:09:52.590933Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes=2):\n",
    "    print('New Model ')\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, progress=True, pretrained_backbone=True)\n",
    "    model.roi_heads.box_predictor.cls_score = torch.nn.Linear(model.roi_heads.box_predictor.cls_score.in_features, num_classes, bias=True)\n",
    "    model.roi_heads.box_predictor.bbox_pred = torch.nn.Linear(model.roi_heads.box_predictor.bbox_pred.in_features, num_classes*4, bias=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T22:55:01.068989Z",
     "start_time": "2020-05-20T22:54:52.711150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model \n"
     ]
    }
   ],
   "source": [
    "#model_path=None\n",
    "#GWD_Model = torch.load(model_path) if model_path else get_model()\n",
    "#GWD_Model.load_state_dict(torch.load('model/model_rc/fasterrcnn_resnet50_fpn_best.pth'))\n",
    "#GWD_Model.to(conf.DEVICE)\n",
    "#EPOCH = int(model_path.split('/')[-1].split('_')[2])+1 if model_path else 0\n",
    "\n",
    "#params = [p for p in GWD_Model.parameters() if p.requires_grad]\n",
    "#optimizer = torch.optim.SGD(params, lr=0.0002,momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T19:59:53.770481Z",
     "start_time": "2020-05-21T19:59:52.261815Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = 'model/model_rc/GWD_EPOCH_19_SCORE_0.0000_LOSS_201.4089.pt'\n",
    "GWD_Model = torch.load(model_path) if model_path else get_model()\n",
    "GWD_Model.to(conf.DEVICE)\n",
    "EPOCH = int(model_path.split('/')[-1].split('_')[2])+1 if model_path else 0\n",
    "\n",
    "params = [p for p in GWD_Model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.001,momentum=0.9, weight_decay=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T23:15:19.923467Z",
     "start_time": "2020-05-21T20:01:02.776526Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267edd3bbed8440f89f915643efa2830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599dc370e58d442196ed3ffb50ed3ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0545b1659e0244acbdf133822c863d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3334966be57a45ff8445a1e9f1b9a429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20054061ae024c85a5487f6f2ffc0c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467f42c0eebe484c9c71284511b9b17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e29262fc2a643c68e8bf49411d67744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bae5b0810942a2b61084a692ef236b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0cf412315c4423b8910346ef809da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a170ec5e3c040a086fbea176758f5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27cbeaad8eb48b0bfe525c96e7c0120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "Some weird shape error due to blank images, but handeled\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_iter=len(WD_Train_Loader)*(EPOCH)\n",
    "\n",
    "for i in tqdm_notebook(range(EPOCH, 30, 1)):\n",
    "    \n",
    "    _epoch_loss=0\n",
    "    _ = GWD_Model.train()\n",
    "    for images, targets in tqdm_notebook(WD_Train_Loader):\n",
    "        \n",
    "        #if not is_contain_blanks(targets):\n",
    "        try:\n",
    "            images = [torch.tensor(image, dtype = torch.float32).to(conf.DEVICE) for image in images]\n",
    "            targets = [{k: torch.tensor(v).to(conf.DEVICE) for k, v in target.items()} for target in targets]\n",
    "\n",
    "            loss_dictionary = GWD_Model(images,targets)\n",
    "            summed_loss = sum(loss for loss in loss_dictionary.values())\n",
    "            summed_loss_value = summed_loss.item()\n",
    "\n",
    "\n",
    "            if math.isfinite(summed_loss_value):\n",
    "                optimizer.zero_grad()\n",
    "                summed_loss.backward()\n",
    "                optimizer.step()\n",
    "                _epoch_loss+=summed_loss_value\n",
    "\n",
    "            else:\n",
    "                print('Loss is undefined:',summed_loss_value,'   skipping BackProp for step no:',_iter)\n",
    "                print(loss_dictionary)\n",
    "\n",
    "\n",
    "            writer.add_scalar('Running Loss/Summed', summed_loss_value, _iter)\n",
    "            writer.add_scalar('Running Loss/Classifier', loss_dictionary['loss_classifier'].item(), _iter)\n",
    "            writer.add_scalar('Running Loss/Box_Regress', loss_dictionary['loss_box_reg'].item(), _iter)\n",
    "            writer.add_scalar('Running Loss/Objectness', loss_dictionary['loss_objectness'].item(), _iter)\n",
    "            writer.add_scalar('Running Loss/RPN_Box_regress', loss_dictionary['loss_rpn_box_reg'].item(), _iter)\n",
    "            \n",
    "        except:\n",
    "            print('Some weird shape error due to blank images, but handeled')\n",
    "        \n",
    "        _iter+=1\n",
    "    scheduler.step()  \n",
    "    torch.save(GWD_Model, 'model/model_rc/'+get_model_name(i, 0, _epoch_loss))\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDet-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:27.375311Z",
     "start_time": "2020-06-14T18:04:19.209697Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import traceback\n",
    "import gc\n",
    "import sys\n",
    "sys.path.insert(1, 'models/EfficientDet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:40.320394Z",
     "start_time": "2020-06-14T18:04:31.259387Z"
    }
   },
   "outputs": [],
   "source": [
    "from edet import edet#, freeze_backbone\n",
    "from efficientdet.loss import FocalLoss\n",
    "from modules.edet_utils import feeze_backbone\n",
    "from modules.edet_utils import WheatDataset_edet, Resizer, Normalizer, collater\n",
    "from config import config\n",
    "conf = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:41.094685Z",
     "start_time": "2020-06-14T18:04:40.390369Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "obj_list = ['wheat']\n",
    "compound_coef = 4\n",
    "model = edet(compound_coef, obj_list)\n",
    "weight_dir = 'D:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\saved_weights\\Edet\\d'+str(compound_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:44.244950Z",
     "start_time": "2020-06-14T18:04:42.689122Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_weight_path = weight_dir+'\\last.pth'\n",
    "try:\n",
    "    ret = model.load_state_dict(torch.load(saved_weight_path) , strict=False)\n",
    "except RuntimeError as e:\n",
    "    print(f'[Warning] Ignoring {e}')\n",
    "    print('\\n\\nThis error caused because last layer size don\\'t match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:44.331921Z",
     "start_time": "2020-06-14T18:04:44.322924Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:57.302414Z",
     "start_time": "2020-06-14T18:04:56.233625Z"
    }
   },
   "outputs": [],
   "source": [
    "mean= [0.485, 0.456, 0.406]\n",
    "std= [0.229, 0.224, 0.225]\n",
    "\n",
    "Data_Transform = transforms.Compose(\n",
    "    [Normalizer(mean=mean, std=std),\n",
    "     Resizer(input_sizes[compound_coef])])\n",
    "\n",
    "WD_Train = WheatDataset_edet(conf, transform = Data_Transform)\n",
    "WD_Valid = WheatDataset_edet(conf, train=False)\n",
    "WD_Train_Loader = DataLoader(WD_Train,\n",
    "                             batch_size=conf.BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             collate_fn=collater)\n",
    "WD_Valid_Loader = DataLoader(WD_Valid,\n",
    "                             batch_size=conf.BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             collate_fn=collater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:04:58.574625Z",
     "start_time": "2020-06-14T18:04:58.092781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[-1.6727, -1.6506, -1.4036],\n",
       "          [-1.6042, -1.5805, -1.3339],\n",
       "          [-1.5014, -1.4755, -1.2293],\n",
       "          ...,\n",
       "          [-1.0390, -0.3375, -0.6367],\n",
       "          [-1.0219, -0.3375, -0.6541],\n",
       "          [-1.0390, -0.3375, -0.6715]],\n",
       " \n",
       "         [[-1.7069, -1.6856, -1.4384],\n",
       "          [-1.6555, -1.6331, -1.3861],\n",
       "          [-1.5528, -1.5280, -1.2816],\n",
       "          ...,\n",
       "          [-1.0562, -0.4251, -0.6367],\n",
       "          [-1.1075, -0.4076, -0.7064],\n",
       "          [-1.1075, -0.4076, -0.7064]],\n",
       " \n",
       "         [[-1.7583, -1.7206, -1.4907],\n",
       "          [-1.7069, -1.6856, -1.4384],\n",
       "          [-1.6213, -1.5980, -1.3513],\n",
       "          ...,\n",
       "          [-1.0733, -0.4426, -0.6018],\n",
       "          [-1.0733, -0.4426, -0.6018],\n",
       "          [-1.0733, -0.4426, -0.6018]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.1589, -1.0903, -0.8807],\n",
       "          [-1.1589, -1.0903, -0.8807],\n",
       "          [-1.1589, -1.0903, -0.8807],\n",
       "          ...,\n",
       "          [ 1.6153,  1.8333,  0.7402],\n",
       "          [ 1.6667,  1.8859,  0.8274],\n",
       "          [ 1.5810,  1.8333,  0.8099]],\n",
       " \n",
       "         [[-1.0904, -1.0203, -0.8110],\n",
       "          [-1.1075, -1.0378, -0.8284],\n",
       "          [-1.1247, -1.0553, -0.8458],\n",
       "          ...,\n",
       "          [ 1.2728,  1.4832,  0.3916],\n",
       "          [ 1.3584,  1.5707,  0.5136],\n",
       "          [ 1.3755,  1.6232,  0.5659]],\n",
       " \n",
       "         [[-1.0390, -0.9853, -0.7587],\n",
       "          [-1.0562, -1.0028, -0.7761],\n",
       "          [-1.0733, -1.0203, -0.7936],\n",
       "          ...,\n",
       "          [ 0.9646,  1.1681,  0.0431],\n",
       "          [ 1.0159,  1.2206,  0.1651],\n",
       "          [ 1.0844,  1.3256,  0.2871]]]),\n",
       " 'annot': tensor([[ 834.,  222.,  890.,  258.,    0.],\n",
       "         [ 226.,  548.,  356.,  606.,    0.],\n",
       "         [ 377.,  504.,  451.,  664.,    0.],\n",
       "         [ 834.,   95.,  943.,  202.,    0.],\n",
       "         [  26.,  144.,  150.,  261.,    0.],\n",
       "         [ 569.,  382.,  688.,  493.,    0.],\n",
       "         [  52.,  602.,  134.,  647.,    0.],\n",
       "         [ 627.,  302.,  749.,  377.,    0.],\n",
       "         [ 412.,  367.,  480.,  449.,    0.],\n",
       "         [ 953.,  220., 1009.,  323.,    0.],\n",
       "         [  30.,   70.,  156.,  203.,    0.],\n",
       "         [  35.,  541.,   81.,  587.,    0.],\n",
       "         [ 103.,   60.,  220.,  143.,    0.],\n",
       "         [ 417.,    4.,  527.,   95.,    0.],\n",
       "         [ 764.,  299.,  883.,  392.,    0.],\n",
       "         [ 539.,   58.,  597.,  188.,    0.],\n",
       "         [ 139.,  274.,  260.,  350.,    0.],\n",
       "         [ 461.,  634.,  579.,  698.,    0.],\n",
       "         [ 215.,  634.,  328.,  709.,    0.],\n",
       "         [ 134.,  903.,  261.,  952.,    0.],\n",
       "         [ 737.,  545.,  824.,  593.,    0.],\n",
       "         [ 292.,  930.,  335.,  976.,    0.],\n",
       "         [   0.,  827.,   86.,  885.,    0.],\n",
       "         [ 324.,   44.,  381.,  114.,    0.],\n",
       "         [ 663.,  794.,  779.,  858.,    0.],\n",
       "         [ 325.,  730.,  401.,  802.,    0.],\n",
       "         [ 155.,  554.,  229.,  624.,    0.],\n",
       "         [ 783.,  833.,  853.,  924.,    0.],\n",
       "         [ 534.,   46.,  607.,  270.,    0.],\n",
       "         [ 155.,  281.,  261.,  419.,    0.],\n",
       "         [ 101.,  240.,  183.,  315.,    0.],\n",
       "         [ 583.,  329.,  663.,  412.,    0.],\n",
       "         [  36.,  595.,  128.,  636.,    0.],\n",
       "         [   0.,  487.,   46.,  558.,    0.],\n",
       "         [  25.,  482.,   76.,  542.,    0.],\n",
       "         [ 160.,  689.,  300.,  763.,    0.],\n",
       "         [ 202.,  702.,  306.,  786.,    0.],\n",
       "         [ 852.,  677.,  967.,  835.,    0.],\n",
       "         [ 904.,  700.,  977.,  820.,    0.],\n",
       "         [ 175.,  866.,  257.,  909.,    0.],\n",
       "         [ 612.,  882.,  827., 1018.,    0.],\n",
       "         [ 675.,  986.,  806., 1024.,    0.],\n",
       "         [ 959.,  869.,  982.,  900.,    0.],\n",
       "         [ 600.,  723.,  821.,  804.,    0.],\n",
       "         [ 575.,  146.,  647.,  267.,    0.],\n",
       "         [ 945.,  193., 1002.,  238.,    0.],\n",
       "         [ 216.,  440.,  262.,  460.,    0.]], dtype=torch.float64),\n",
       " 'scale': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WD_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:05:12.023115Z",
     "start_time": "2020-06-14T18:05:12.003121Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelWithLoss(nn.Module):\n",
    "    def __init__(self, model, debug=False):\n",
    "        super().__init__()\n",
    "        self.criterion = FocalLoss()\n",
    "        self.model = model\n",
    "        self.debug = debug\n",
    "\n",
    "    def forward(self, imgs, annotations, obj_list=None):\n",
    "        _, regression, classification, anchors = self.model(imgs)\n",
    "        if self.debug:\n",
    "            cls_loss, reg_loss = self.criterion(classification, regression, anchors, annotations,\n",
    "                                                imgs=imgs, obj_list=obj_list)\n",
    "        else:\n",
    "            cls_loss, reg_loss = self.criterion(classification, regression, anchors, annotations)\n",
    "        return cls_loss, reg_loss\n",
    "model = ModelWithLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T18:05:58.200449Z",
     "start_time": "2020-06-14T18:05:50.182969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2af1731918d42f4a35e483bc4c9193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2698), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 93, in forward\n",
      "    x = self._project_conv(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils_extra.py\", line 44, in forward\n",
      "    x = F.pad(x, [left, right, top, bottom])\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 3391, in _pad\n",
      "    return _VF.constant_pad_nd(input, pad, value)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.31 GiB already allocated; 14.83 MiB free; 9.47 GiB reserved in total by PyTorch)\n",
      "\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.31 GiB already allocated; 14.83 MiB free; 9.47 GiB reserved in total by PyTorch)\n",
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 81, in forward\n",
      "    x = self._depthwise_conv(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils_extra.py\", line 44, in forward\n",
      "    x = F.pad(x, [left, right, top, bottom])\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 3391, in _pad\n",
      "    return _VF.constant_pad_nd(input, pad, value)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.28 GiB already allocated; 4.58 MiB free; 9.46 GiB reserved in total by PyTorch)\n",
      "\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.28 GiB already allocated; 4.58 MiB free; 9.46 GiB reserved in total by PyTorch)\n",
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 93, in forward\n",
      "    x = self._project_conv(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils_extra.py\", line 44, in forward\n",
      "    x = F.pad(x, [left, right, top, bottom])\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 3391, in _pad\n",
      "    return _VF.constant_pad_nd(input, pad, value)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 12.00 GiB total capacity; 9.07 GiB already allocated; 4.16 MiB free; 9.23 GiB reserved in total by PyTorch)\n",
      "\n",
      "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 12.00 GiB total capacity; 9.07 GiB already allocated; 4.16 MiB free; 9.23 GiB reserved in total by PyTorch)\n",
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 83, in forward\n",
      "    x = self._swish(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils.py\", line 54, in forward\n",
      "    return SwishImplementation.apply(x)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils.py\", line 41, in forward\n",
      "    result = i * torch.sigmoid(i)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.30 GiB already allocated; 12.98 MiB free; 9.46 GiB reserved in total by PyTorch)\n",
      "\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.30 GiB already allocated; 12.98 MiB free; 9.46 GiB reserved in total by PyTorch)\n",
      "[Error] Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-98f2bf198274>\", line 30, in <module>\n",
      "    cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-9-b16f1436717e>\", line 9, in forward\n",
      "    _, regression, classification, anchors = self.model(imgs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\backbone.py\", line 65, in forward\n",
      "    _, p3, p4, p5 = self.backbone_net(inputs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientdet\\model.py\", line 412, in forward\n",
      "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\model.py\", line 83, in forward\n",
      "    x = self._swish(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils.py\", line 54, in forward\n",
      "    return SwishImplementation.apply(x)\n",
      "  File \"models/EfficientDet\\efficientnet\\utils.py\", line 41, in forward\n",
      "    result = i * torch.sigmoid(i)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.30 GiB already allocated; 18.83 MiB free; 9.46 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 12.00 GiB total capacity; 9.30 GiB already allocated; 18.83 MiB free; 9.46 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-98f2bf198274>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mcls_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mcls_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mreg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-b16f1436717e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, imgs, annotations, obj_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             cls_loss, reg_loss = self.criterion(classification, regression, anchors, annotations,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\backbone.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mmax_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\efficientdet\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\efficientnet\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mx_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mx_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_se_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mx_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[0mx_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_se_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\efficientnet\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMemoryEfficientSwish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSwishImplementation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Kaggle\\Global-Wheat-Detction-Kaggle-2020\\models\\EfficientDet\\efficientnet\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, i)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/Edet_4_Test_run\")\n",
    "model.train()\n",
    "model.to(conf.DEVICE)\n",
    "\n",
    "last_epoch = 0\n",
    "# TODO: Extract last epoch from saved model name\n",
    "current_iter = max(0, last_epoch*len(WD_Train_Loader))\n",
    "\n",
    "for epoch in range(last_epoch, 2, 1):\n",
    "\n",
    "    epoch_loss = []\n",
    "    progress_bar = tqdm(WD_Train_Loader)\n",
    "        \n",
    "    for _, data in enumerate(progress_bar):\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # TODO: targets to required format\n",
    "        try:\n",
    "            \n",
    "            images = data['img']\n",
    "            targets = data['annot']\n",
    "\n",
    "            images = images.to(conf.DEVICE)\n",
    "            targets = targets.to(conf.DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            cls_loss, reg_loss = model(images, targets, obj_list=obj_list)\n",
    "            cls_loss = cls_loss.mean()\n",
    "            reg_loss = reg_loss.mean()\n",
    "\n",
    "            loss = cls_loss + reg_loss\n",
    "            if loss == 0 or not torch.isfinite(loss):\n",
    "                print('loss is 0 or infinite')\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(float(loss))\n",
    "\n",
    "            current_iter+=1\n",
    "            writer.add_scalar('Running Loss/Summed', loss, current_iter)\n",
    "            writer.add_scalar('Running Loss/Classifier', cls_loss, current_iter)\n",
    "            writer.add_scalar('Running Loss/Box_Regress', reg_loss, current_iter)\n",
    "            writer.add_scalar('Running LR', optimizer.param_groups[0]['lr'], current_iter)\n",
    "\n",
    "            progress_bar.set_description(\n",
    "                'Epoch: {}, Images: {}, Cls_loss: {:.5f}, Reg_loss: {:.5f}, Total_loss: {:.5f}'\n",
    "                .format(epoch, _ * conf.BATCH_SIZE, cls_loss.item(),reg_loss.item(), loss.item()))\n",
    "\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print('[Error]', traceback.format_exc())\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "    save_model_path = 'GWD_EDET{}_EPOCH_{}_SCORE_{:.5f}_LOSS_{:.5f}.pth'.format(compound_coef, epoch, 0, np.mean(epoch_loss))\n",
    "    torch.save(model.state_dict(), weight_dir+'/'+save_model_path)\n",
    "    torch.save(model.state_dict(), weight_dir+'/last.pth')\n",
    "    print('model_saved')\n",
    "    scheduler.step(np.mean(epoch_loss))\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T02:02:19.047087Z",
     "start_time": "2020-06-22T02:02:19.035090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GWD', 'FRCNN', '0', 'EPOCH', '0', 'SCORE', '0', 'LOSS', '0.pth']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'saved_weights/fasterrcnn/GWD_FRCNN_0_EPOCH_0_SCORE_0_LOSS_0.pth'.split('/')[-1].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:34:11.016608Z",
     "start_time": "2020-06-15T02:34:11.009610Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'models/detr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:34:14.257673Z",
     "start_time": "2020-06-15T02:34:11.770212Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.backbone import build_backbone\n",
    "from models.transformer import build_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T01:16:22.039749Z",
     "start_time": "2020-06-15T01:16:22.033751Z"
    }
   },
   "outputs": [],
   "source": [
    "class args():\n",
    "    #device = 'cuda'\n",
    "    lr=1e-4\n",
    "    lr_backbone=1e-5\n",
    "    batch_size=2\n",
    "    weight_decay=1e-4\n",
    "    epochs=300\n",
    "    lr_drop=200\n",
    "    clip_max_norm=0.1\n",
    "    frozen_weights', type=str, default=None\n",
    "    backbone', default='resnet50\n",
    "    dilation', action='store_true\n",
    "    position_embedding', default='sine\n",
    "    enc_layers', default=6\n",
    "    dec_layers', default=6\n",
    "    dim_feedforward', default=2048\n",
    "    hidden_dim', default=256\n",
    "    dropout', default=0.1\n",
    "    nheads', default=8\n",
    "    num_queries', default=100\n",
    "    pre_norm', action='store_true'\n",
    "    masks', action='store_true\n",
    "    no_aux_loss', dest='aux_loss', action='store_false'\n",
    "    set_cost_class', default=1\n",
    "    set_cost_bbox', default=5\n",
    "    set_cost_giou', default=2\n",
    "    mask_loss_coef', default=1\n",
    "    dice_loss_coef', default=1\n",
    "    bbox_loss_coef', default=5\n",
    "    giou_loss_coef', default=2\n",
    "    eos_coef', default=0.1\n",
    "    dataset_file', default='coco'\n",
    "    \n",
    "    coco_path', type=str)\n",
    "    parser.add_argument('--coco_panoptic_path', type=str)\n",
    "    parser.add_argument('--remove_difficult', action='store_true')\n",
    "    \n",
    "    output_dir', default=''\n",
    "    device', default='cuda'\n",
    "    seed', default=42\n",
    "    resume', default=''\n",
    "    start_epoch', default=0\n",
    "    eval', action='store_true'\n",
    "    num_workers', default=2\n",
    "    world_size', default=1\n",
    "    dist_url', default='env://'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T01:16:39.445638Z",
     "start_time": "2020-06-15T01:16:39.435639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = args()\n",
    "args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:43:04.896508Z",
     "start_time": "2020-06-15T02:43:04.888509Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.position_encoding import PositionEmbeddingSine, PositionEmbeddingLearned\n",
    "from models.backbone import Backbone, Joiner\n",
    "from models.transformer import Transformer\n",
    "from models.detr import DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:41:18.303422Z",
     "start_time": "2020-06-15T02:41:15.021477Z"
    }
   },
   "outputs": [],
   "source": [
    "N_steps = 256//2\n",
    "position_embedding = PositionEmbeddingLearned(N_steps)\n",
    "#position_embedding = PositionEmbeddingSine(N_steps, normalize=True)\n",
    "backbone = Backbone('resnet101', True, False, True)  #(name, train_backbone, inter_layers(for seg.), dialation)\n",
    "model = Joiner(backbone, position_embedding)\n",
    "model.num_channels = backbone.num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:40:22.402327Z",
     "start_time": "2020-06-15T02:40:21.840509Z"
    }
   },
   "outputs": [],
   "source": [
    "trans = Transformer(d_model=256,\n",
    "                    dropout=0.1,\n",
    "                    nhead=8,\n",
    "                    dim_feedforward=2048,\n",
    "                    num_encoder_layers=6,\n",
    "                    num_decoder_layers=6,\n",
    "                    normalize_before=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:45:45.044065Z",
     "start_time": "2020-06-15T02:45:45.017074Z"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = DETR(model, trans, num_classes=1, num_queries=100, aux_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:45:59.861198Z",
     "start_time": "2020-06-15T02:45:59.836206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DETR(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_embed): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (bbox_embed): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (query_embed): Embedding(100, 256)\n",
       "  (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (backbone): Joiner(\n",
       "    (0): Backbone(\n",
       "      (body): IntermediateLayerGetter(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (6): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (7): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (8): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (9): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (10): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (11): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (12): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (13): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (14): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (15): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (16): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (17): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (18): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (19): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (20): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (21): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (22): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PositionEmbeddingLearned(\n",
       "      (row_embed): Embedding(50, 128)\n",
       "      (col_embed): Embedding(50, 128)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:35:39.470680Z",
     "start_time": "2020-06-15T02:35:39.463682Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:35:40.562546Z",
     "start_time": "2020-06-15T02:35:40.548551Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('DETR training and evaluation script', parents=[get_args_parser()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:35:42.305299Z",
     "start_time": "2020-06-15T02:35:42.298306Z"
    }
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:35:43.239388Z",
     "start_time": "2020-06-15T02:35:43.229391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(aux_loss=True, backbone='resnet50', batch_size=2, bbox_loss_coef=5, clip_max_norm=0.1, coco_panoptic_path=None, coco_path=None, dataset_file='coco', dec_layers=6, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', dropout=0.1, enc_layers=6, eos_coef=0.1, epochs=300, eval=False, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, lr=0.0001, lr_backbone=1e-05, lr_drop=200, mask_loss_coef=1, masks=False, nheads=8, num_queries=100, num_workers=2, output_dir='', position_embedding='sine', pre_norm=False, remove_difficult=False, resume='', seed=42, set_cost_bbox=5, set_cost_class=1, set_cost_giou=2, start_epoch=0, weight_decay=0.0001, world_size=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:48:04.912831Z",
     "start_time": "2020-06-15T02:48:04.903833Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.backbone import build_backbone\n",
    "from models.transformer import build_transformer\n",
    "from main import get_args_parser\n",
    "from models.detr import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
